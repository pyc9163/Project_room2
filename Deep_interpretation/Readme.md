# Deep learning 모델의 해석

  인공신경망 모델의 한 가지 특징은 블랙박스라는 것이다. 내부를 볼 수 없는 즉, 결과에 대한 해석이 어렵다 라고 알려져 있다.
  비교적 복잡하지 않은 머신러닝의 경우 어느정도 해석이 가능하다는 점이 있지만, Deep 한 layer를 사용해서 학습하는 모델의 경우 해석이 더더욱 어려워 진다.
  하지만 인공신경망 모델을 더 효과적으로 사용하기 위해선 결과에 대한 해석은 필수이다. 이에 해석 기법을 알아보고 실 사용 예제를 커밋해 본다.



- variable_dropout
- PDP plot
- deep_interpretation
- Lime

